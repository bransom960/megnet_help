{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 13)\n"
     ]
    }
   ],
   "source": [
    "from openbabel import openbabel\n",
    "from openbabel import pybel\n",
    "import openbabel\n",
    "import sys\n",
    "import pymatgen\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import tensorflow as tf\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.models import GraphModel\n",
    "from tensorflow.keras import optimizers\n",
    "from megnet.data.molecule import MolecularGraph\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "nfeat_bond = 100\n",
    "r_cutoff = 10\n",
    "gaussian_centers = np.linspace(0, r_cutoff + 1, nfeat_bond)\n",
    "gaussian_width = 0.5\n",
    "\n",
    "\n",
    "#BUILD MODEL\n",
    "\n",
    "smiles = np.loadtxt('smiles.csv', dtype=str,delimiter = ',')\n",
    "state_attributes = np.loadtxt('Reaxys_n.csv', delimiter = ',')\n",
    "Dy_bin = np.loadtxt('y_bin.csv',delimiter = ',')\n",
    "cutoff = 0.7\n",
    "                \n",
    "# #gives a molecule structure\n",
    "structures =[]\n",
    "failed_smi = []\n",
    "for smi in smiles:\n",
    "    try:\n",
    "        structures.append(pybel.readstring(\"smi\",smi))\n",
    "    except:\n",
    "        failed_smi.append(list(np.ravel(smiles)).index(smi))\n",
    "print(np.shape(state_attributes))\n",
    "Dy_bin = Dy_bin.astype('float32')\n",
    "Dy_bin = [j for i,j in enumerate(Dy_bin) if i not in failed_smi]\n",
    "state_attributes = np.delete(state_attributes,failed_smi,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bransom/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_9:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/bransom/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_9:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_8:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/bransom/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_27:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_26:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/bransom/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_27:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_26:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast_2:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/bransom/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_atom/Reshape_45:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_atom/Reshape_44:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_atom/Cast_4:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/home/bransom/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:435: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/set2set_bond/Reshape_45:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/set2set_bond/Reshape_44:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/set2set_bond/Cast_4:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 15s 15s/step - loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:megnet.callbacks:Nan loss found!\n",
      "INFO:megnet.callbacks:Load weights callback/val_mae_00882_0.009824.hdf5\n",
      "INFO:megnet.callbacks:Now lr is 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cad9b38fceb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtarget_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     model.train_from_graphs(train_graphs=graph_train, train_targets = target_train, \n\u001b[0m\u001b[1;32m     50\u001b[0m                        validation_graphs=graph_validation,validation_targets=target_validation)#,\n\u001b[1;32m     51\u001b[0m                             \u001b[0;31m#epochs=100, verbose=0,batch_size=100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/megnet/models/base.py\u001b[0m in \u001b[0;36mtrain_from_graphs\u001b[0;34m(self, train_graphs, train_targets, validation_graphs, validation_targets, sample_weights, epochs, batch_size, verbose, callbacks, prev_model, lr_scaling_factor, patience, save_checkpoint, automatic_correction, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0msteps_per_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_graphs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         self.fit(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programs/anaconda3/envs/tf-8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "graphs_valid = []\n",
    "targets_valid = []\n",
    "structures_invalid = []\n",
    "del_materials =[]\n",
    "x=0\n",
    "\n",
    "\n",
    "model = MEGNetModel(graph_converter = MolecularGraph(),centers = gaussian_centers,width = gaussian_width,\n",
    "                   nfeat_node=27,nfeat_edge=27,nfeat_global=len(state_attributes[0]))\n",
    "\n",
    "for s, p in zip(structures, Dy_bin):\n",
    "    try:\n",
    "        graph = model.graph_converter.convert(s,state_attributes = [list(state_attributes[x])])\n",
    "        if np.any(np.isinf(graph['bond']))==False and np.any(np.isinf(graph['atom']))==False and np.any(np.isinf(graph['state']))==False:\n",
    "            for i in range(len(graph['atom'])):\n",
    "                graph['atom'][i] = [float(y) for y in graph['atom'][i]]\n",
    "            graphs_valid.append(graph)\n",
    "\n",
    "            targets_valid.append(p)\n",
    "        else:\n",
    "            graphs_valid.append(graph)\n",
    "            targets_valid.append(p)\n",
    "    except:\n",
    "        structures_invalid.append(s)\n",
    "        del_materials.append(x)\n",
    "    x+=1\n",
    "\n",
    "Dy_bin = [j for i,j in enumerate(Dy_bin) if i not in del_materials]\n",
    "\n",
    "graphs_valid = np.array(graphs_valid)\n",
    "targets_valid_split = np.array(Dy_bin)\n",
    "targets_valid = tf.keras.utils.to_categorical(np.array(Dy_bin))\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "predicted_y = []\n",
    "for train_index, test_index in skf.split(graphs_valid,targets_valid_split):\n",
    "    pots = int(len(train_index)*.8)\n",
    "    \n",
    "    graphs = np.array(graphs_valid[train_index])\n",
    "    targets = np.array(targets_valid[train_index])\n",
    "    \n",
    "    graph_train = graphs[:pots]\n",
    "    graph_validation = graphs[pots:]\n",
    "    target_train = tf.keras.utils.to_categorical(targets[:pots])\n",
    "    target_validation = tf.keras.utils.to_categorical(targets[pots:])\n",
    "    \n",
    "    model.train_from_graphs(train_graphs=graph_train, train_targets = target_train, \n",
    "                       validation_graphs=graph_validation,validation_targets=target_validation)#,\n",
    "                            #epochs=100, verbose=0,batch_size=100)\n",
    "    predicted_y.extend([model.predict_graph(x) for x in graphs[test_index]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(targets_valid, predicted_y)\n",
    "\n",
    "# Add the y=x line\n",
    "lim = [min(ax.get_xlim() + ax.get_ylim()), max(ax.get_xlim() + ax.get_ylim())]\n",
    "ax.set_xlim((-0.05,1.05))\n",
    "ax.set_ylim((-0.05,1.05))\n",
    "ax.plot(lim, lim, 'k--')\n",
    "\n",
    "ax.set_xlabel('baseline')\n",
    "ax.set_ylabel('predicted')\n",
    "\n",
    "fig.set_size_inches(5,5)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.show()\n",
    "\n",
    "plt.savefig(Label+'.png')\n",
    "predicted_y_scaled = [1 if i>cutoff else 0 for i in predicted_y]\n",
    "targets_valid_scaled = [1 if i>cutoff else 0 for i in targets_valid]\n",
    "cm = confusion_matrix(targets_alid_scaled, predicted_y_scaled)\n",
    "TP,TN,FP,FN = cm[1,1],cm[0,0],cm[0,1],cm[1,0]\n",
    "\n",
    "comp = sum([1 for i in list(range(len(predicted_y))) if predicted_y_scaled[i] == targets_alid_scaled[i]])\n",
    "accuracy = comp/len(pred_y)\n",
    "\n",
    "print('Accuracy = ',str(accuracy),' Precision = ',str(TP/(TP+FP)),' Recall = ',str(TP/(TP+FN)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-8",
   "language": "python",
   "name": "tf-8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
